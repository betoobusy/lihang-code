{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4章 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1．朴素贝叶斯法是典型的生成学习方法。生成方法由训练数据学习联合概率分布\n",
    "$P(X,Y)$，然后求得后验概率分布$P(Y|X)$。具体来说，利用训练数据学习$P(X|Y)$和$P(Y)$的估计，得到联合概率分布：\n",
    "\n",
    "$$P(X,Y)＝P(Y)P(X|Y)$$\n",
    "\n",
    "概率估计方法可以是极大似然估计或贝叶斯估计。\n",
    "\n",
    "2．朴素贝叶斯法的基本假设是条件独立性，\n",
    "\n",
    "$$\\begin{aligned} P(X&=x | Y=c_{k} )=P\\left(X^{(1)}=x^{(1)}, \\cdots, X^{(n)}=x^{(n)} | Y=c_{k}\\right) \\\\ &=\\prod_{j=1}^{n} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right) \\end{aligned}$$\n",
    "\n",
    "\n",
    "这是一个较强的假设。由于这一假设，模型包含的条件概率的数量大为减少，朴素贝叶斯法的学习与预测大为简化。因而朴素贝叶斯法高效，且易于实现。其缺点是分类的性能不一定很高。\n",
    "\n",
    "3．朴素贝叶斯法利用贝叶斯定理与学到的联合概率模型进行分类预测。\n",
    "\n",
    "$$P(Y | X)=\\frac{P(X, Y)}{P(X)}=\\frac{P(Y) P(X | Y)}{\\sum_{Y} P(Y) P(X | Y)}$$\n",
    " \n",
    "将输入$x$分到后验概率最大的类$y$。\n",
    "\n",
    "$$y=\\arg \\max _{c_{k}} P\\left(Y=c_{k}\\right) \\prod_{j=1}^{n} P\\left(X_{j}=x^{(j)} | Y=c_{k}\\right)$$\n",
    "\n",
    "后验概率最大等价于0-1损失函数时的期望风险最小化。\n",
    "\n",
    "\n",
    "模型：\n",
    "\n",
    "- 高斯模型\n",
    "- 多项式模型\n",
    "- 伯努利模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np# 导入numpy工具包并命名为np\n",
    "import pandas as pd# 导入pandas工具包并命名为pd\n",
    "import matplotlib.pyplot as plt# 导入matplotlib工具包中的pyplot模块并命名为plt\n",
    "%matplotlib inline # 使matplotlib绘制结果能够呈现在jupyternotebook中\n",
    "\n",
    "from sklearn.datasets import load_iris  # 导入鸢尾花数据集\n",
    "from sklearn.model_selection import train_test_split# 导入train_test_split方法\n",
    "\n",
    "from collections import Counter # 导入Counter类\n",
    "import math # 导入math模块用于数学计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "def create_data():\n",
    "    iris = load_iris() # 读取鸢尾花数据集\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names) # 将鸢尾花数据转化为pandas数据框，并将特征名称设置为指定的名称\n",
    "    df['label'] = iris.target  # 新增一列标签信息\n",
    "    df.columns = [  # 重命名数据框的列名\n",
    "        'sepal length', 'sepal width', 'petal length', 'petal width', 'label'\n",
    "    ]\n",
    "    data = np.array(df.iloc[:100, :]) # 取前100个样本数据\n",
    "    # print(data)\n",
    "    return data[:, :-1], data[:, -1] # 分别返回特征数据和标签数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data() # 调用create_data函数获取数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 分割数据为训练集和测试集，其中test_size参数控制测试集占总数据集的比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.7, 2.6, 3.5, 1. ]), 1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0], y_test[0] # 打印测试集的第一个样本特征和标签信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
    "\n",
    "## GaussianNB 高斯朴素贝叶斯\n",
    "\n",
    "特征的可能性被假设为高斯\n",
    "\n",
    "概率密度函数：\n",
    "$$P(x_i | y_k)=\\frac{1}{\\sqrt{2\\pi\\sigma^2_{yk}}}exp(-\\frac{(x_i-\\mu_{yk})^2}{2\\sigma^2_{yk}})$$\n",
    "\n",
    "数学期望(mean)：$\\mu$\n",
    "\n",
    "方差：$\\sigma^2=\\frac{\\sum(X-\\mu)^2}{N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:# 定义一个高斯朴素贝叶斯分类器类\n",
    "    def __init__(self):\n",
    "        self.model = None # 分类器模型初始化为空\n",
    "\n",
    "    # 数学期望\n",
    "    @staticmethod# 在def方法中没有引用对象的资源时，要加上这个\n",
    "    def mean(X):# 这表明mean这个函数里面不需要调用self.的对象和调用\n",
    "        return sum(X) / float(len(X))# 计算特征数据X的数学期望\n",
    "\n",
    "    # 标准差（方差）X是所有样本同一特征下的各个值\n",
    "    def stdev(self, X): # 这里就不能加@staticmethod，因为他要用刚才定义好的函数mean\n",
    "        avg = self.mean(X) # 计算特征数据X的数学期望\n",
    "        return math.sqrt(sum([pow(x - avg, 2) for x in X]) / float(len(X)))# 根据公式计算X的标准差（方差）\n",
    "\n",
    "     # 概率密度函数  x结构为一个数据，其格式为[第一个特征, 第二个特征]\n",
    "    def gaussian_probability(self, x, mean, stdev):\n",
    "        exponent = math.exp(-(math.pow(x - mean, 2) /\n",
    "                              (2 * math.pow(stdev, 2)))) # 计算概率密度函数的指数项\n",
    "        return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent # 计算概率密度函数的值\n",
    "\n",
    "    # 处理X_train\n",
    "    def summarize(self, train_data): # train_data结构为[array[5.0, 0.37],array[3.42, 0.40],array[3.42, 0.40],[12, 0.40]..]\n",
    "        \"\"\"\n",
    "        对每一种特征数据进行数学期望和标准差求和，获得每个特征数据在每个类别下的数值均值和标准差集合\n",
    "        zip(*)作用将train_data转置\n",
    "        \"\"\"\n",
    "        summaries = [(self.mean(i), self.stdev(i)) for i in zip(*train_data)] \n",
    "        # 变为 [array[5.0, 3.42, 12], array[0.37, 0.4, 0.4]]\n",
    "        return summaries\n",
    "\n",
    "    # 分类别求出数学期望和标准差,   self.model的数据结构{类别1：第一个特征期望和方差，第二个特征的期望和方差\n",
    "    #                                                    类别2：第一个特征期望和方差，第二个特征的期望和方差\n",
    "    def fit(self, X, y):\n",
    "        labels = list(set(y)) # 获得标签集合      集合是{} 列表是[] 所以要list回来\n",
    "        data = {label: [] for label in labels} # 创建个字典，每个键的值是列表\n",
    "        for f, label in zip(X, y): # zip将对象相应位置元素打包成元组，然后返回元组组成的列表，结构为(array([X]), y),...\n",
    "            data[label].append(f)  # 将相同标签的特征数据存储在同一个列表中  \n",
    "            # 构建data{y1:[array(x1),array(x2),..],y2:[array(x1),array(x2),..]..}\n",
    "        self.model = {\n",
    "            label: self.summarize(value) # 对每个标签下的特征数据集合，进行数学期望与标准差求和，确定模型中每个标签下每个特征数据的数学期望和标准差\n",
    "            for label, value in data.items()\n",
    "        }\n",
    "        return 'gaussianNB train done!' # 返回训练完成的提示信息\n",
    "\n",
    "    # 计算概率\n",
    "    def calculate_probabilities(self, input_data):\n",
    "        # summaries:{0.0: [(5.0, 0.37),(3.42, 0.40)], 1.0: [(5.8, 0.449),(2.7, 0.27)]}\n",
    "        # input_data:[1.1, 2.2]\n",
    "        probabilities = {} # 创建一个空字典，用于存储输入特征数据属于不同标签的概率\n",
    "        for label, value in self.model.items():\n",
    "            probabilities[label] = 1  # 初始化概率为1，后面计算会叠乘\n",
    "            for i in range(len(value)):\n",
    "                mean, stdev = value[i]\n",
    "                probabilities[label] *= self.gaussian_probability( # 赋值时对先前的概率叠乘P(x1|y)，获取输入数据属于每个类别的概率\n",
    "                    input_data[i], mean, stdev)\n",
    "        return probabilities\n",
    "\n",
    "    # 类别\n",
    "    def predict(self, X_test):\n",
    "        # {0.0: 2.9680340789325763e-27, 1.0: 3.5749783019849535e-26}\n",
    "        label = sorted( # 将输入数据X_test的概率按照从小到大排序\n",
    "            self.calculate_probabilities(X_test).items(),\n",
    "            key=lambda x: x[-1])[-1][0]  # 取出概率最大的标签\n",
    "        return label  # 返回预测的类别\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        right = 0   # 初始化正确率为0\n",
    "        for X, y in zip(X_test, y_test):# 对每个测试数据，通过计算其预测标签，与真实标签做对比\n",
    "            label = self.predict(X)\n",
    "            if label == y: # 如果预测标签和真实标签相一致，即计算正确率\n",
    "                right += 1\n",
    "\n",
    "        return right / float(len(X_test))# 定义函数的返回值。函数返回的是测试集中分类正确的数量除以测试集实例的总数，即准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayes() # 创建一个名为model的NaiveBayes类实例，用于执行朴素贝叶斯算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gaussianNB train done!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train) # 使用训练集(X_train, y_train)对朴素贝叶斯模型进行训练，使其学习特征和标签之间的关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([4.4,  3.2,  1.3,  0.2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test) # 计算模型在测试集(X_test, y_test)上的准确率，即正确分类数与总测试数之比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### scikit-learn实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB # 引入GaussianNB类，该类是sklearn库中实现高斯朴素贝叶斯分类算法的类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB() # 创建GaussianNB类对象clf，这个对象将用于训练模型和进行预测。\n",
    "clf.fit(X_train, y_train) # 使用训练数据(X_train, y_train)对模型进行训练，其中X_train表示包含训练数据的特征值的二维数组，y_train表示包含训练数据目标分类的一维数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)# 用测试数据(X_test, y_test)来衡量模型的精确性，计算模型在测试数据上的准确率，即正确分类的样本数与测试集中总样本数之比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[4.4,  3.2,  1.3,  0.2]]) # 使用训练好的模型进行预测。传入待预测数据(4.4, 3.2, 1.3, 0.2)，模型将会预测这组数据所属的鸢尾花品种。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB # 伯努利模型和多项式模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第4章朴素贝叶斯法-习题\n",
    "\n",
    "### 习题4.1\n",
    "&emsp;&emsp;用极大似然估计法推出朴素贝叶斯法中的概率估计公式(4.8)及公式 (4.9)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "**第1步：**证明公式(4.8)：$\\displaystyle P(Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k)}{N}$  \n",
    "由于朴素贝叶斯法假设$Y$是定义在输出空间$\\mathcal{Y}$上的随机变量，因此可以定义$P(Y=c_k)$概率为$p$。  \n",
    "令$\\displaystyle m=\\sum_{i=1}^NI(y_i=c_k)$，得出似然函数：$$L(p)=f_D(y_1,y_2,\\cdots,y_n|\\theta)=\\binom{N}{m}p^m(1-p)^{(N-m)}$$使用微分求极值，两边同时对$p$求微分：$$\\begin{aligned}\n",
    "0 &= \\binom{N}{m}\\left[mp^{(m-1)}(1-p)^{(N-m)}-(N-m)p^m(1-p)^{(N-m-1)}\\right] \\\\\n",
    "& = \\binom{N}{m}\\left[p^{(m-1)}(1-p)^{(N-m-1)}(m-Np)\\right]\n",
    "\\end{aligned}$$可求解得到$\\displaystyle p=0,p=1,p=\\frac{m}{N}$  \n",
    "显然$\\displaystyle P(Y=c_k)=p=\\frac{m}{N}=\\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k)}{N}$，公式(4.8)得证。\n",
    "\n",
    "----\n",
    "\n",
    "**第2步：**证明公式(4.9)：$\\displaystyle P(X^{(j)}=a_{jl}|Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k)}{\\displaystyle \\sum_{i=1}^N I(y_i=c_k)}$  \n",
    "令$P(X^{(j)}=a_{jl}|Y=c_k)=p$，令$\\displaystyle m=\\sum_{i=1}^N I(y_i=c_k), q=\\sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k)$，得出似然函数：$$L(p)=\\binom{m}{q}p^q(i-p)^{m-q}$$使用微分求极值，两边同时对$p$求微分：$$\\begin{aligned}\n",
    "0 &= \\binom{m}{q}\\left[qp^{(q-1)}(1-p)^{(m-q)}-(m-q)p^q(1-p)^{(m-q-1)}\\right] \\\\\n",
    "& = \\binom{m}{q}\\left[p^{(q-1)}(1-p)^{(m-q-1)}(q-mp)\\right]\n",
    "\\end{aligned}$$可求解得到$\\displaystyle p=0,p=1,p=\\frac{q}{m}$  \n",
    "显然$\\displaystyle P(X^{(j)}=a_{jl}|Y=c_k)=p=\\frac{q}{m}=\\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k)}{\\displaystyle \\sum_{i=1}^N I(y_i=c_k)}$，公式(4.9)得证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题4.2\n",
    "&emsp;&emsp;用贝叶斯估计法推出朴素贝叶斯法中的慨率估计公式(4.10)及公式(4.11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "**第1步：**证明公式(4.11)：$\\displaystyle P(Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k) + \\lambda}{N+K \\lambda}$  \n",
    "加入先验概率，在没有任何信息的情况下，可以假设先验概率为均匀概率（即每个事件的概率是相同的）。  \n",
    "可得$\\displaystyle p=\\frac{1}{K} \\Leftrightarrow pK-1=0\\quad(1)$  \n",
    "根据习题4.1得出先验概率的极大似然估计是$\\displaystyle pN - \\sum_{i=1}^N I(y_i=c_k) = 0\\quad(2)$  \n",
    "存在参数$\\lambda$使得$(1) \\cdot \\lambda + (2) = 0$  \n",
    "所以有$$\\lambda(pK-1) + pN - \\sum_{i=1}^N I(y_i=c_k) = 0$$可得$\\displaystyle P(Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k) + \\lambda}{N+K \\lambda}$，公式(4.11)得证。  \n",
    "\n",
    "----\n",
    "\n",
    "**第2步：**证明公式(4.10)：$\\displaystyle P_{\\lambda}(X^{(j)}=a_{jl} | Y = c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k) + \\lambda}{\\displaystyle \\sum_{i=1}^N I(y_i=c_k) + S_j \\lambda}$   \n",
    "根据第1步，可同理得到$$\n",
    "P(Y=c_k, x^{(j)}=a_{j l})=\\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k, x_i^{(j)}=a_{jl})+\\lambda}{N+K S_j \\lambda}$$  \n",
    "$$\\begin{aligned} \n",
    "P(x^{(j)}=a_{jl} | Y=c_k)\n",
    "&= \\frac{P(Y=c_k, x^{(j)}=a_{j l})}{P(y_i=c_k)} \\\\\n",
    "&= \\frac{\\displaystyle \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k, x_i^{(j)}=a_{jl})+\\lambda}{N+K S_j \\lambda}}{\\displaystyle \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k) + \\lambda}{N+K \\lambda}} \\\\\n",
    "&= (\\lambda可以任意取值，于是取\\lambda = S_j \\lambda) \\\\\n",
    "&= \\frac{\\displaystyle \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k, x_i^{(j)}=a_{jl})+\\lambda}{N+K S_j \\lambda}}{\\displaystyle \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k) + \\lambda}{N+K S_j \\lambda}} \\\\ \n",
    "&= \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k, x_i^{(j)}=a_{jl})+\\lambda}{\\displaystyle \\sum_{i=1}^N I(y_i=c_k) + \\lambda} (其中\\lambda = S_j \\lambda)\\\\\n",
    "&= \\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k) + \\lambda}{\\displaystyle \\sum_{i=1}^N I(y_i=c_k) + S_j \\lambda}\n",
    "\\end{aligned} $$  \n",
    "公式(4.11)得证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "参考代码：https://github.com/wzyonggege/statistical-learning-method\n",
    "\n",
    "本文代码更新地址：https://github.com/fengdu78/lihang-code\n",
    "\n",
    "习题解答：https://github.com/datawhalechina/statistical-learning-method-solutions-manual\n",
    "\n",
    "中文注释制作：机器学习初学者公众号：ID:ai-start-com\n",
    "\n",
    "配置环境：python 3.5+\n",
    "\n",
    "代码全部测试通过。\n",
    "![gongzhong](../gongzhong.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
